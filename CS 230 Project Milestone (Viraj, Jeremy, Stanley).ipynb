{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d3a969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac3dd563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>outcome</th>\n",
       "      <th>chart_labeled_date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon, 07 Nov 2022 02:44:03 GMT</td>\n",
       "      <td>SOCIAL WORK ASSESSMENT    Robert Wesley is a 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>215</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon, 07 Nov 2022 02:44:11 GMT</td>\n",
       "      <td>SOCIAL WORK FOLLOW UP NOTE     Chart reviewed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon, 07 Nov 2022 02:49:25 GMT</td>\n",
       "      <td>New Patient Visit  Ashley Busch is a 29 Y fema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>360</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon, 07 Nov 2022 02:57:29 GMT</td>\n",
       "      <td>SW met with pt at bedside. Present was Interpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>360</td>\n",
       "      <td>True</td>\n",
       "      <td>Mon, 07 Nov 2022 02:58:26 GMT</td>\n",
       "      <td>Received SBAR regarding pt's admission. Pt is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  uniq_id  patient_id  outcome             chart_labeled_date  \\\n",
       "0           1        1         215     True  Mon, 07 Nov 2022 02:44:03 GMT   \n",
       "1           2        2         215     True  Mon, 07 Nov 2022 02:44:11 GMT   \n",
       "2           3        3         220     True  Mon, 07 Nov 2022 02:49:25 GMT   \n",
       "3           4        4         360     True  Mon, 07 Nov 2022 02:57:29 GMT   \n",
       "4           5        5         360     True  Mon, 07 Nov 2022 02:58:26 GMT   \n",
       "\n",
       "                                                text  \n",
       "0  SOCIAL WORK ASSESSMENT    Robert Wesley is a 5...  \n",
       "1  SOCIAL WORK FOLLOW UP NOTE     Chart reviewed,...  \n",
       "2  New Patient Visit  Ashley Busch is a 29 Y fema...  \n",
       "3  SW met with pt at bedside. Present was Interpr...  \n",
       "4  Received SBAR regarding pt's admission. Pt is ...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"combined_data_v3.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c362556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes irrevelant columns from the original data\n",
    "df = df.drop(['patient_id', 'uniq_id', 'chart_labeled_date', 'Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0be57e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>SOCIAL WORK ASSESSMENT    Robert Wesley is a 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>SOCIAL WORK FOLLOW UP NOTE     Chart reviewed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>New Patient Visit  Ashley Busch is a 29 Y fema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>SW met with pt at bedside. Present was Interpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>Received SBAR regarding pt's admission. Pt is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome                                               text\n",
       "0     True  SOCIAL WORK ASSESSMENT    Robert Wesley is a 5...\n",
       "1     True  SOCIAL WORK FOLLOW UP NOTE     Chart reviewed,...\n",
       "2     True  New Patient Visit  Ashley Busch is a 29 Y fema...\n",
       "3     True  SW met with pt at bedside. Present was Interpr...\n",
       "4     True  Received SBAR regarding pt's admission. Pt is ..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9728f37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SOCIAL WORK ASSESSMENT    Robert Wesley is a 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SOCIAL WORK FOLLOW UP NOTE     Chart reviewed,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>New Patient Visit  Ashley Busch is a 29 Y fema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>SW met with pt at bedside. Present was Interpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Received SBAR regarding pt's admission. Pt is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome                                               text\n",
       "0        1  SOCIAL WORK ASSESSMENT    Robert Wesley is a 5...\n",
       "1        1  SOCIAL WORK FOLLOW UP NOTE     Chart reviewed,...\n",
       "2        1  New Patient Visit  Ashley Busch is a 29 Y fema...\n",
       "3        1  SW met with pt at bedside. Present was Interpr...\n",
       "4        1  Received SBAR regarding pt's admission. Pt is ..."
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replaces True and Falses with 1 and 0 to make outcome more straightforward\n",
    "df = df.replace(True, 1)\n",
    "df = df.replace(False, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "076f42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using train test split, we split the text into training, validation, and test sets\n",
    "\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['outcome'], \n",
    "                                                                    random_state=2022, \n",
    "                                                                    test_size=0.6, \n",
    "                                                                    stratify=df['outcome'])\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2022, \n",
    "                                                                test_size=0.4, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "42d6526f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import pretrained BERT model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1ced7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "max_sentence = 100\n",
    "\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_sentence,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_sentence,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_sentence,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "25c9b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists to tensors and adds attention mask \n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "275af5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d3de5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters for fine-tuning \n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "308997a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "        # relu activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # fully connected layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "        # fully connected layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward propagation\n",
    "    def forward(self, sent_id, mask):\n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "      \n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8c35800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our architecture\n",
    "model = BERT_Arch(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6ff4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b517559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer from huggingface transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = 1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "45161314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1675a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# pushes to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "201ead06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    \n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        # progress update after every 50 batches\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        \n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    " \n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward propagation to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0 to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "732d0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    \n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            \n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d207a7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.700\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 2 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.690\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 3 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.690\n",
      "Validation Loss: 0.692\n",
      "\n",
      " Epoch 4 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.693\n",
      "Validation Loss: 0.692\n",
      "\n",
      " Epoch 5 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.698\n",
      "Validation Loss: 0.691\n",
      "\n",
      " Epoch 6 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.683\n",
      "Validation Loss: 0.691\n",
      "\n",
      " Epoch 7 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.688\n",
      "Validation Loss: 0.691\n",
      "\n",
      " Epoch 8 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.691\n",
      "Validation Loss: 0.690\n",
      "\n",
      " Epoch 9 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.685\n",
      "Validation Loss: 0.690\n",
      "\n",
      " Epoch 10 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.675\n",
      "Validation Loss: 0.689\n",
      "\n",
      " Epoch 11 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.694\n",
      "Validation Loss: 0.689\n",
      "\n",
      " Epoch 12 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.690\n",
      "Validation Loss: 0.689\n",
      "\n",
      " Epoch 13 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.691\n",
      "Validation Loss: 0.688\n",
      "\n",
      " Epoch 14 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.681\n",
      "Validation Loss: 0.688\n",
      "\n",
      " Epoch 15 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.682\n",
      "Validation Loss: 0.687\n",
      "\n",
      " Epoch 16 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.687\n",
      "Validation Loss: 0.687\n",
      "\n",
      " Epoch 17 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.678\n",
      "Validation Loss: 0.687\n",
      "\n",
      " Epoch 18 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.684\n",
      "Validation Loss: 0.686\n",
      "\n",
      " Epoch 19 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.685\n",
      "Validation Loss: 0.686\n",
      "\n",
      " Epoch 20 / 20\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.679\n",
      "Validation Loss: 0.685\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ed9ea6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a9d259dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81        42\n",
      "           1       0.67      0.29      0.40        21\n",
      "\n",
      "    accuracy                           0.71        63\n",
      "   macro avg       0.69      0.61      0.61        63\n",
      "weighted avg       0.70      0.71      0.68        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ed6b5",
   "metadata": {},
   "source": [
    "We based our model on multiple sources:\n",
    "1. https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\n",
    "2. https://huggingface.co/docs/transformers/training\n",
    "3. https://www.kaggle.com/code/harshjain123/bert-for-everyone-tutorial-implementation\n",
    "4. https://www.tensorflow.org/tfmodels/nlp/fine_tune_bert\n",
    "\n",
    "We plan to use this perfomance as a baseline to compare against when we add our project novelty (applying in-context learning to BERT) to see if our addition improves performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
